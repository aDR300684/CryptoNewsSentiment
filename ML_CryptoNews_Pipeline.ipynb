{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c38fa5a-a8d8-401d-a973-3541e20c17a8",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "In this project, a detailed machine learning pipeline named `ML_CryptoNews_Pipeline` has been developed to systematically analyze news articles related to cryptocurrencies. The pipeline integrates advanced Natural Language Processing (NLP) techniques for text data preprocessing and employs FinBERT, a financial-context-specific adaptation of the BERT model, for sentiment analysis. The objective is to predict cryptocurrency price momentum by analyzing the sentiment and content of these articles.\n",
    "\n",
    "A comprehensive exploration of machine learning models was undertaken to identify the most effective approach for predicting price momentum. This exploration included the evaluation and hyperparameter tuning of various models, namely Random Forest, Support Vector Machine (SVM), Gradient Boosting Machine (GBM), and Deep Neural Networks (DNN). The accuracies obtained on the test set for these models were as follows: Random Forest achieved an accuracy of 0.6081330868761553, SVM reached 0.5982747997535428, GBM recorded 0.6130622304374614, and DNN achieved 0.607516943930992.\n",
    "\n",
    "Based on these evaluations, the Gradient Boosting Machine (GBM) model was selected for inclusion in the pipeline due to its superior performance in terms of accuracy on the test set.\n",
    "\n",
    "### Core Components\n",
    "\n",
    "The pipeline integrates several key components:\n",
    "\n",
    "- **Comprehensive Sentiment Analysis**:\n",
    "\n",
    "    - **General Sentiment with FinBERT**: At the forefront of our sentiment analysis, we utilize FinBERT, a BERT model specifically fine-tuned for financial contexts, to assess the overall sentiment conveyed in cryptocurrency news articles. FinBERT's advanced capabilities allow us to classify the content into positive, neutral, or negative sentiment categories, providing an initial layer of insight into market sentiment.\n",
    "    - **Aspect-Based Sentiment Analysis**: To complement and deepen our understanding, the pipeline further incorporates aspect-based sentiment analysis. This approach examines specific segments or aspects within the articles, identifying nuanced sentiments associated with particular topics or entities mentioned in the text. Utilizing SpaCy for extracting noun chunks and FinBERT for sentiment evaluation, we obtain weighted sentiment scores and proportions of positive, neutral, and negative sentiments for different aspects. This dual-layered analysis ensures a richer, more granular sentiment assessment, crucial for understanding the multifaceted nature of news impact on market dynamics.\n",
    "\n",
    "- **Topic Modeling via LDA**: Beyond sentiment, understanding the thematic content of news articles is crucial. We employ Latent Dirichlet Allocation (LDA) for topic modeling, identifying dominant topics and themes. This analysis provides valuable insights into the focal points of discourse within the cryptocurrency market, enriching our predictive model with contextual depth.\n",
    "\n",
    "- **Price Momentum Prediction**: The essence of our pipeline is its ability to predict cryptocurrency price movements based on the comprehensive sentiment and thematic analyses performed. By leveraging Gradient Boosting Machine (GBM) trained with historical data, we aim to correlate the nuanced sentiment assessments and thematic insights with market price behaviors.\n",
    "\n",
    "This enriched sentiment analysis framework, paired with advanced topic modeling and predictive capabilities, forms the backbone of our `ML_CryptoNews_Pipeline`. It exemplifies our commitment to leveraging machine learning and NLP techniques to distill actionable insights from cryptocurrency news, aiming to offer a sophisticated tool for market analysis and prediction.\n",
    "\n",
    "### Project Deliverables\n",
    "\n",
    "This project which demonstrates an end-to-end data science workflow, includes data ingestion, processing, modeling, and generating actionable insights. Each article processed through the pipeline is evaluated for sentiment (positive, neutral, negative) and predicted price momentum (likely to rise, likely to drop), providing comprehensive market insights.\n",
    "\n",
    "### Model Performance and Real-World Application\n",
    "\n",
    "It is important to note that the current models achieve an accuracy of approximately 61%. While this demonstrates some predictive capability, it falls short of the reliability required for real-world financial decision-making. Consequently, the project should be viewed as an educational exerciseâ€”a demonstration of how to construct a machine learning workflow from scratch, encompassing data preprocessing, modeling, and interpretation within the fascinating context of cryptocurrency markets.\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "Despite the limitations in model accuracy, this project lays a solid foundation for further exploration and improvement. Future work could involve refining the models, exploring additional features, and incorporating more complex NLP techniques to better capture the nuances of financial news sentiment and its impact on market movements.\n",
    "\n",
    "This project was developed as part of the final portfolio for the Machine Learning career path at Codecademy, aimed at mastering the workflow of machine learning projects from initial concept to actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb6fd19-d979-48af-b8ca-87d5c4bb9569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adrco\\Final_Project-env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive. Price will likely rise.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# Ignore specific warning categories\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import spacy\n",
    "\n",
    "# Load trained models\n",
    "lda_model = joblib.load('C:/Users/adrco/Final_Project-env/LDA_Model/lda_model.pkl')\n",
    "tfidf_vectorizer = joblib.load('C:/Users/adrco/Final_Project-env/TF-IDF_Vectorizer/tfidf_vectorizer.pkl')\n",
    "word2vec_model = Word2Vec.load('C:/Users/adrco/Final_Project-env/Word2Vec_Model/word2vec_model.model')\n",
    "gbm_best_model = joblib.load('C:/Users/adrco/Final_Project-env/GBM_Model/gbm_best_model.joblib')\n",
    "\n",
    "# Load the scaler trained on the training data\n",
    "X_train = joblib.load(\"C:/Users/adrco/Final_Project-env/Datasets/Splits/X_train_updated.pkl\")\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Setup FinBERT\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "finbert_pipeline = pipeline(\"sentiment-analysis\", model=finbert_model, tokenizer=finbert_tokenizer)\n",
    "\n",
    "# Load SpaCy for aspect-based sentiment analysis\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def get_lda_features(text):\n",
    "    # Transform the text to tf-idf features\n",
    "    tfidf_features = tfidf_vectorizer.transform([text])\n",
    "    # Get the LDA topic distribution for the tf-idf features\n",
    "    lda_features = lda_model.transform(tfidf_features)[0]\n",
    "    \n",
    "    # Determine the Dominant Topic (plus 1 for 1-based indexing, if needed)\n",
    "    dominant_topic = np.argmax(lda_features) + 1\n",
    "    \n",
    "    # Return both the lda_features and the dominant topic\n",
    "    return lda_features, dominant_topic\n",
    "\n",
    "def get_word2vec_features(text):\n",
    "    words = word_tokenize(text)\n",
    "    vector_size = word2vec_model.vector_size\n",
    "    word_vectors = np.zeros((vector_size,), dtype=\"float32\")\n",
    "    for word in words:\n",
    "        if word in word2vec_model.wv:\n",
    "            word_vectors += word2vec_model.wv[word]\n",
    "    return word_vectors / len(words) if words else word_vectors\n",
    "\n",
    "def analyze_sentiment_with_finbert(text):\n",
    "    result = finbert_pipeline(text)[0]\n",
    "    sentiment_score = {'positive': 1, 'neutral': 0, 'negative': -1}.get(result['label'], 0)\n",
    "    return sentiment_score\n",
    "\n",
    "def aspect_based_analysis(text):\n",
    "    doc = nlp(text)\n",
    "    aspects = [chunk.text for chunk in doc.noun_chunks]\n",
    "    aspect_sentiments = [analyze_sentiment_with_finbert(aspect) for aspect in aspects]\n",
    "    weighted_score = np.mean(aspect_sentiments) if aspect_sentiments else 0\n",
    "    positive_prop = aspect_sentiments.count(1) / len(aspect_sentiments) if aspect_sentiments else 0\n",
    "    neutral_prop = aspect_sentiments.count(0) / len(aspect_sentiments) if aspect_sentiments else 0\n",
    "    negative_prop = aspect_sentiments.count(-1) / len(aspect_sentiments) if aspect_sentiments else 0\n",
    "    return weighted_score, positive_prop, neutral_prop, negative_prop\n",
    "\n",
    "def prepare_features(text):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    # Capturing both LDA features and the dominant topic\n",
    "    lda_features, dominant_topic = get_lda_features(preprocessed_text)\n",
    "    word2vec_features = get_word2vec_features(preprocessed_text)\n",
    "    finbert_score = analyze_sentiment_with_finbert(text)\n",
    "    weighted_score, positive_prop, neutral_prop, negative_prop = aspect_based_analysis(text)\n",
    "    \n",
    "    # Including the dominant topic as a feature\n",
    "    all_features = np.hstack([\n",
    "        lda_features,  # Topic distribution weights\n",
    "        [dominant_topic],  # Dominant Topic as a single feature\n",
    "        word2vec_features,  # Word2Vec features\n",
    "        [finbert_score, weighted_score, positive_prop, neutral_prop, negative_prop]  # Sentiment scores\n",
    "    ])\n",
    "    \n",
    "    # Ensuring the feature vector is 2D (1 sample x N features)\n",
    "    all_features = all_features.reshape(1, -1)\n",
    "\n",
    "    scaled_features = scaler.transform(all_features)  # Directly use 2D array for transformation\n",
    "    \n",
    "    \n",
    "    return scaled_features\n",
    "\n",
    "def predict_and_output(new_text):\n",
    "    scaled_features = prepare_features(new_text)\n",
    "    prediction = gbm_best_model.predict(scaled_features)[0]\n",
    "    \n",
    "    # Analyze sentiment score using FinBERT directly for the output message\n",
    "    sentiment_score = analyze_sentiment_with_finbert(new_text)\n",
    "    sentiment_label = 'neutral'\n",
    "    if sentiment_score > 0:\n",
    "        sentiment_label = 'positive'\n",
    "    elif sentiment_score < 0:\n",
    "        sentiment_label = 'negative'\n",
    "    \n",
    "    # Combining both the sentiment analysis and price movement prediction in the output\n",
    "    price_movement_prediction = \"Price will likely rise.\" if prediction == 1 else \"Price will likely drop.\"\n",
    "    return f\"Sentiment: {sentiment_label}. {price_movement_prediction}\"\n",
    "\n",
    "# Example usage, paste any news article text here:\n",
    "new_text = \"Bitcoin Surges to New Heights: A New Era for Cryptocurrency Investors. In an unprecedented rally, Bitcoin has once again proven its resilience and potential for investors worldwide. The cryptocurrency giant has not only surpassed previous records but has also instilled renewed confidence among its supporters. Experts attribute this surge to a combination of factors including increased adoption by mainstream financial institutions, positive regulatory news, and a growing recognition of Bitcoin as a 'digital gold' in times of economic uncertainty. This positive momentum is seen as a significant milestone for Bitcoin and the wider cryptocurrency market, signaling a strong future ahead.\"\n",
    "print(predict_and_output(new_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385be70-73eb-4e74-9a24-18ae67229198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
